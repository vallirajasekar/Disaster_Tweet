{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0b203bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbdb15d9",
   "metadata": {},
   "source": [
    "## Downloading the Data from Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4c898be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfbdf09",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "741eec09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "91924fda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 5)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8f14cc1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id             0\n",
       "keyword       61\n",
       "location    2533\n",
       "text           0\n",
       "target         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "19ca1282",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['id','keyword','location'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a648b3cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'target', 'clean_text'], dtype='object')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c6c36151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    4342\n",
       "1    3271\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2becd44",
   "metadata": {},
   "source": [
    "## Preprocessing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b86d6c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f0ab6cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/vallirajasekar/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/vallirajasekar/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/vallirajasekar/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download NLTK resources\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "96f02b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Convert to Lowercase\n",
    "    text=text.lower()\n",
    "    # Remove punctuation\n",
    "    text=re.sub(r'[^\\w\\s]','',text)\n",
    "    # Tokenize text\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    # Lemmatize words\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    return ' '.join(tokens)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ebf19e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_text'] = df['text'].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "85ae1817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Our Deeds are the Reason of this #earthquake M...\n",
       "1               Forest fire near La Ronge Sask. Canada\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'][:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33003ab",
   "metadata": {},
   "source": [
    "## Converting into Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "12134194",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize the vectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "# Vectorize the 'clean_text' column\n",
    "X = vectorizer.fit_transform(df['clean_text'])\n",
    "\n",
    "# Target variable\n",
    "y = df['target']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1c3a4d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ca11da09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tfidf_vectorizer.pkl']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(vectorizer, 'tfidf_vectorizer.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8deb407a",
   "metadata": {},
   "source": [
    "## Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "80b64b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "38c7194e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Initialize the classifier\n",
    "clf = MultinomialNB()\n",
    "\n",
    "# Train the classifier\n",
    "clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fafd9af0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['multinomial_nb_classifier.pkl']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(clf, 'multinomial_nb_classifier.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f1a76d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8010505581089954\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.88      0.84       874\n",
      "           1       0.82      0.69      0.75       649\n",
      "\n",
      "    accuracy                           0.80      1523\n",
      "   macro avg       0.80      0.79      0.79      1523\n",
      "weighted avg       0.80      0.80      0.80      1523\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the testing set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796d2e85",
   "metadata": {},
   "source": [
    "## Predicting for New Word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480f58c7",
   "metadata": {},
   "source": [
    "## Preprocessing the New Tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "39bfeb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tweet = \"beware world ablaze sierra leone &amp; guap.\"\n",
    "\n",
    "# Preprocess the new tweet\n",
    "clean_new_tweet = preprocess_text(new_tweet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b8cf7c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = vectorizer.transform([clean_new_tweet])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0e9479ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Sentiment: Not a Real Disaster\n"
     ]
    }
   ],
   "source": [
    "# Predict the sentiment of the new tweet\n",
    "predicted_sentiment = clf.predict(X_new)\n",
    "\n",
    "# Map the predicted sentiment to human-readable label\n",
    "sentiment_label = \"Real Disaster\" if predicted_sentiment == 1 else \"Not a Real Disaster\"\n",
    "\n",
    "print(\"Predicted Sentiment:\", sentiment_label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e0b10b",
   "metadata": {},
   "source": [
    "## Preprocessing the Next text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f2b00cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=pd.read_csv('/Users/vallirajasekar/Desktop/NLP_Challenge/Disaster_Tweet/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "733102cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.drop(['id','keyword','location'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7a6ef124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>EARTHQUAKE SAFETY LOS ANGELES ÛÒ SAFETY FASTE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>Storm in RI worse than last hurricane. My city...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>Green Line derailment in Chicago http://t.co/U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>MEG issues Hazardous Weather Outlook (HWO) htt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>#CityofCalgary has activated its Municipal Eme...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3263 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text\n",
       "0                    Just happened a terrible car crash\n",
       "1     Heard about #earthquake is different cities, s...\n",
       "2     there is a forest fire at spot pond, geese are...\n",
       "3              Apocalypse lighting. #Spokane #wildfires\n",
       "4         Typhoon Soudelor kills 28 in China and Taiwan\n",
       "...                                                 ...\n",
       "3258  EARTHQUAKE SAFETY LOS ANGELES ÛÒ SAFETY FASTE...\n",
       "3259  Storm in RI worse than last hurricane. My city...\n",
       "3260  Green Line derailment in Chicago http://t.co/U...\n",
       "3261  MEG issues Hazardous Weather Outlook (HWO) htt...\n",
       "3262  #CityofCalgary has activated its Municipal Eme...\n",
       "\n",
       "[3263 rows x 1 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f3b2a7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['clean_text'] = df_test['text'].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e16445a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_new = vectorizer.transform(df_test['clean_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "347fe336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the sentiment for the new tweets\n",
    "y_pred_new = clf.predict(X_test_new)\n",
    "\n",
    "# Map the predicted sentiment to human-readable labels\n",
    "predicted_sentiments = [\"Real Disaster\" if sentiment == 1 else \"Not a Real Disaster\" for sentiment in y_pred_new]\n",
    "\n",
    "# Add the predicted sentiments to df_test\n",
    "df_test['predicted_sentiment'] = predicted_sentiments\n",
    "\n",
    "# Display the DataFrame with predicted sentiments\n",
    "#print(df_test[['text', 'predicted_sentiment']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "bda200d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>predicted_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "      <td>happened terrible car crash</td>\n",
       "      <td>Real Disaster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "      <td>heard earthquake different city stay safe ever...</td>\n",
       "      <td>Real Disaster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "      <td>forest fire spot pond goose fleeing across str...</td>\n",
       "      <td>Real Disaster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "      <td>apocalypse lighting spokane wildfire</td>\n",
       "      <td>Real Disaster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "      <td>typhoon soudelor kill 28 china taiwan</td>\n",
       "      <td>Real Disaster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>EARTHQUAKE SAFETY LOS ANGELES ÛÒ SAFETY FASTE...</td>\n",
       "      <td>earthquake safety los angeles ûò safety fasten...</td>\n",
       "      <td>Real Disaster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>Storm in RI worse than last hurricane. My city...</td>\n",
       "      <td>storm ri worse last hurricane cityamp3others h...</td>\n",
       "      <td>Not a Real Disaster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>Green Line derailment in Chicago http://t.co/U...</td>\n",
       "      <td>green line derailment chicago httptcoutbxlcbiuy</td>\n",
       "      <td>Real Disaster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>MEG issues Hazardous Weather Outlook (HWO) htt...</td>\n",
       "      <td>meg issue hazardous weather outlook hwo httptc...</td>\n",
       "      <td>Real Disaster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>#CityofCalgary has activated its Municipal Eme...</td>\n",
       "      <td>cityofcalgary activated municipal emergency pl...</td>\n",
       "      <td>Real Disaster</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3263 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "0                    Just happened a terrible car crash   \n",
       "1     Heard about #earthquake is different cities, s...   \n",
       "2     there is a forest fire at spot pond, geese are...   \n",
       "3              Apocalypse lighting. #Spokane #wildfires   \n",
       "4         Typhoon Soudelor kills 28 in China and Taiwan   \n",
       "...                                                 ...   \n",
       "3258  EARTHQUAKE SAFETY LOS ANGELES ÛÒ SAFETY FASTE...   \n",
       "3259  Storm in RI worse than last hurricane. My city...   \n",
       "3260  Green Line derailment in Chicago http://t.co/U...   \n",
       "3261  MEG issues Hazardous Weather Outlook (HWO) htt...   \n",
       "3262  #CityofCalgary has activated its Municipal Eme...   \n",
       "\n",
       "                                             clean_text  predicted_sentiment  \n",
       "0                           happened terrible car crash        Real Disaster  \n",
       "1     heard earthquake different city stay safe ever...        Real Disaster  \n",
       "2     forest fire spot pond goose fleeing across str...        Real Disaster  \n",
       "3                  apocalypse lighting spokane wildfire        Real Disaster  \n",
       "4                 typhoon soudelor kill 28 china taiwan        Real Disaster  \n",
       "...                                                 ...                  ...  \n",
       "3258  earthquake safety los angeles ûò safety fasten...        Real Disaster  \n",
       "3259  storm ri worse last hurricane cityamp3others h...  Not a Real Disaster  \n",
       "3260    green line derailment chicago httptcoutbxlcbiuy        Real Disaster  \n",
       "3261  meg issue hazardous weather outlook hwo httptc...        Real Disaster  \n",
       "3262  cityofcalgary activated municipal emergency pl...        Real Disaster  \n",
       "\n",
       "[3263 rows x 3 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccc5959",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a72697",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bcd3f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
